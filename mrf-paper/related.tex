\section{Related work}
\label{sec:related-work}

\noindent%
\textbf{Superlinear scaling.} %
Amdahl's famous scaling law \cite{10.1145/1465482.1465560}, asserting sublinear speedup and diminishing returns for parallelization, is a cornerstone result in distributed computing \cite{10.1145/42411.42415, 10.5555/775339.775386}. This is thanks to its wide applicability, ranging from dimensioning distributed systems \cite{1580395} to guiding performance optimization efforts \cite{10.5555/1951599, 10.1145/42411.42415}. During the almost 60 years since its first publication, several violations of the scaling law have been reported from various application areas, triggering the several extensions to sizing VLSI layouts \cite{4563876} and heterogeneous computing systems \cite{6280307}, characterizing failures \cite{406581}, energy usage \cite{6163449}, and retrograde scaling \cite{10.5555/1951599} in large-scale computing systems, etc. One phenomenon that seems to have defied all attempts to be captured by a general scaling law is faster-than-linear scaling, which reported from a broad range of real workloads including database systems \cite{scalability-analyzed, 10.5555/1012889.1012894}, SDN analytics \cite{sdn-analytitcs}, high-performance computing \cite{556383, 7733347, 6483679}, multi-robot systems \cite{10.1007/978-3-319-77610-1}, information retrieval systems \cite{dobb-1, dobb-2}, etc. For instance, \cite{scalability-analyzed} shows superlinear speedup experienced when scaling PostgreSQL 9.1 to multiple CPUs and traces back the reason to a new ``cache plan'' for locally storing compiled SQL queries at each thread. Another report shows that dense matrix multiplication may show faster-than-linear speedup when matrix rows\slash columns are optimized for exploiting CPU caches \cite{7733347}: more CPUs means more CPU case, yielding the surprising scaling effect. Perhaps closes to a new model explaining superlinear growth are \cite{7733347, 80148}; here, the authors present several general architectural patterns that may lead to superlinear speedup (e.g., non-persistent algorithms, extending cache space, job scheduling, etc.) and give general models for characterizing speedup in each case. These works have been the first to identify the most important ingredients in superlinear speedup: do disproportionately less work in each worker as we scale the system \cite{7733347}, or add more resources, e.g., caches, per thread \cite{80148}. The former ``scaled size'' model \cite{556383} is the main trait we capitalize on in our work.  So far, however, each attempt to systematically \emph{reproduce} superlinear scaling, beyond merely \emph{observing} and \emph{explaining} it, have been specific to particular use cases \cite{556383} or relying on larger caches and mere luck \cite{556383}. During that time there have been growing concerns whether superlinear scaling even exists in real-life applications \cite{10.1016/0167-8191(86)90024-4}: for instance, Gunther (the father of the ``Universal Scalaility Law'') proves an earlier report on faster-than-linear scaling observed in large-scale a Hadoop MapReduce workload is attributable to a methodological benchmarking error and, when measured the right way, reduces to a sublinear scaling trend. This prompts him to conclude that superlinearity is ultimately a performance illusion, which goes against the very laws of thermodynamics. This is despite that superlinear growth is often found in nature, e.g., the scaling of human communities to large cities follows a faster-than-linear trend \cite{PhysRevE.79.016115}. To the best of our knowledge, this is the first time that a systematic design methodology is presented for network applications to reach it.

\noindent%
\textbf{Locality-boosting load balancing.} %
As one of the main ingredients of our distributed self-adjusting systems architecture, locality-boosting load balancing helps improving the input locality in the per-worker request streams 

\begin{itemize}
\item NICs increasingly used to intelligently move data between the network, CPU, GPU and accelerators \cite{sherry-ccr23}
\item Linux contains a comprehensive toolset to tune the way packets are dispatched to CPUs \cite{rss-linux}
\item plain RSS is static, RSS++ is a load and state-aware receive side scaling mechanism aiming to keep CPU load constant \cite{10.1145/3359989.3365412}
\item Reframer can be used to reorder packets for improving temporal locality \cite{276946,246322}
\item rule partitioning: Hicuts \cite{820051}, Hypercuts \cite{10.1145/863955.863980}, Efficuts \cite{10.1145/1851182.1851208}, CutSplit \cite{8485947} build a decision tree, with each node representing a ``cut'' of the rule-space, whose leaf nodes store only a small number of rules. A linear search among these rules yields the desired matching. The cuts are designed so that the rule lists in the leaves are as small as possible, with the least possible rules replicated in multiple lists. We argue that these cuts could be reused in our multicore classifier to partition the rule set, and represented in the NIC as Receive Flow Steering (RFS) filters
\item In fact, our classifier can be viewed as a parallel extension to these schemes, just with ``dumb'' hash-based cuts for traversing the decision tree in one step and maintaining the rule lists in the leaves in a self-adjusting list. It is a surprising finding that such a simple extension of Hicuts \cite{820051}, Hypercuts \cite{10.1145/863955.863980}, Efficuts \cite{10.1145/1851182.1851208}, CutSplit \cite{8485947} can yield superlinear scaling
\item SAX-PAC \cite{10.1145/2619239.2626294} can be used to decompose a rule set with many dependencies into a set of independent rule sets: this should recover superlinearity
\end{itemize}

\noindent%
\textbf{Self-adjusting data structures.} %
\begin{itemize}
\item Self-adjusting data structures are widely used in algorithms and computer systems
\item simplest SA algorithms are caches; often used in distributed computing: predictive state caching in NFs \cite{295537}, SQL caches: redis, memcached \cite{10.5555/1012889.1012894, 180324}, distributed web caching and CDNs \cite{295603}, dataplane kv store caching \cite{ghigoff2021bmc}, query result caching in microservices \cite{295493}
\item to what extent these achieve superlinear scaling is an open question
\item MTF: building block of a self-adjusting algorithm for computing point maxima and convex hulls \cite{BentleyCL93}, program compilation and interpretation \cite{HesterH85}, detecting collisions in hash tables~\cite{HesterH85}, and data compression \cite{BentleySTW86}
\item the problem of cache management can be viewed as a self-adjusting list rearrangement problem \cite{SleatorT85}
\item further self-adjusting data structures include splay trees \cite{SleatorT85Splay}, self-adjusting skip lists \cite{BoseDL08}, push-down trees \cite{Avin0020}, or self-adjusting trees for storing geometric data \cite{ParkM12}
\item these are all candidates to be used, along with a proper locality boosting load balancer, to reach superlinear scaling in distributed applications
\end{itemize}

%   Models of self-adjusting data structures are based on the cost of access and rearrangement. For example:

%   \begin{enumerate}
%   \item \textbf{Self-adjusting lists}~\cite{SleatorT85}. We are given a set of items, arranged in a linear list, and a sequence of access requests $\sigma$ to the nodes of the list.
%     Upon receiving an access request to a node in
%     the list, an algorithm searches linearly through the list, starting
%     from the head of the list, traversing nodes until encountering the
%     accessed node. Accessing the node at position i in the list costs i
%     (the first node is at position 1).
%     After serving a request, an algorithm may
%     choose to rearrange the nodes of the list, paying the cost 1 per each transposition of neighboring items. 


%   \item \textbf{Binary search trees}~\cite{SleatorT85Splay}.
%     When the universe of items is ordered, we may store them in a binary search tree.
%     A classic binary search tree is a \emph{splay tree}~\cite{SleatorT85Splay}.
%     Another important search tree is $O(\log \log n)$-competitive \emph{tango tree}~\cite{demaine2007dyynamic}.
%     The dynamic optimality conjecture~\cite{SleatorT85Splay} (does an $O(1)$-competitive algorithm exist?) is a major unresolved question, in contrast to the simpler self-adjusting lists setting.
%     Splay trees have other properties, e.g. working set bounds, static optimality~\cite{SleatorT85Splay} and other.



%   \item \textbf{Other self-adjusting data structures}. 
%     Self-adjusting skip lists~\cite{BoseDL08} have an equivalent of the working set bound of splay trees.
%     Push-down trees~\cite{Avin0020} are dynamically optimal and have the working set bound.
%     Adaptive geometric space partitioning data structures exist, e.g. self-adjusting trees for storing geometric data~\cite{ParkM12}.
%     The online metrical task system model~\cite{Borodin1992} underpins all these models, and captures generalizations such as caching, which has self-adjusting algorithms such as LRU~\cite{SleatorT85}.
%   \end{enumerate}


% %   Other examples: intrusion detection as mtflist, flow table lookup as splay tree, etc.
% %   Each have their own challenges, and our model is just an example.

%   \paragraph*{Locality.}
%   Common inputs have high locality, i.e. the same items are accessed repeatedly.
%   The locality parameter of input is often the determining factor for the performance of self-adjusting data structures (e.g. there exist arguments of locality for self-adjusting lists~\cite{AlbersL16}, working set bounds for splay trees~\cite{SleatorT85Splay} and paging~\cite{AlbersFG05}).


%   \subsection{Load Balancing and Scaling}

%   \paragraph*{Load balancing with random hash functions.}
%   A random load balancing assignment function is sufficient to load-balance correctly.
%   Gonnet~\cite{Gonnet81} proved that when throwing $n$ balls uniformly and independently at random into $n$ bins, the fullest bin has
%   load $(1 + o(1)) \log n/ \log \log n$ in expectation.
%   The maximum bin load with this approach is $O(\log n/ \log \log n)$ with high probability~\cite{DubhashiR98}.

%   \paragraph*{Practical load balancing.}
%   RSS+ paper~\cite{10.1145/3359989.3365412}.

%   \subsection{Packet classification}

%   Various data structures for packet classification were proposed in the literature: lists, tries, hash tables, bit vectors, or decision trees~\cite{gupta2001algorithms,Srinivasan1999,Eppstein2001}, as well as hardware solutions (TCAM).
%   Packet classifiers are often accompanied by caching systems that provide some adjustability to traffic.
%   Due to its simplicity, a~linear lookup structure is commonly applied in practice, e.g., in the default firewall suite of the Linux operating system kernel called \texttt{iptables}~\cite{MianoBRBLP19}, the OpenFlow reference switch~\cite{openflow}, and in many QoS classifiers.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "distributed_mrf"
%%% End:

