%\documentclass{hotnets22}
% \documentclass[sigconf,10pt]{acmart}
\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix-2020-09}
\usepackage{amsmath}
\usepackage{amsthm}

\usepackage{times}  
\usepackage{hyperref}
% \usepackage{subfig}
\usepackage{tikz}
\usetikzlibrary{math}
\usepackage{pgfplots}
\usepackage{pgfplotstable}

\usepackage{subcaption}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{array}

\newcolumntype{s}{>{\hsize=.3\hsize\linewidth=\hsize}X}
\newcolumntype{D}{>{\hsize=.3\hsize\linewidth=\hsize}X}

\newcommand{\wdImg}{\dimexpr \linewidth-2\tabcolsep} %width of the image

\hypersetup{pdfstartview=FitH,pdfpagelayout=SinglePage}

\setlength\paperheight {11in}
\setlength\paperwidth {8.5in}
\setlength{\textwidth}{7in}
\setlength{\textheight}{9.25in}
\setlength{\oddsidemargin}{-.25in}
\setlength{\evensidemargin}{-.25in}

\newcommand{\rg}[1]{\textcolor{blue}{(\textbf{GR:} #1)}}

% we have a big fig
\renewcommand{\floatpagefraction}{.8}%
% \renewcommand{\topfraction}{.8}
% \renewcommand{\bottomfraction}{.8}

% TODO: remove for the CR!
% \pagestyle{plain}
% \settopmatter{printfolios=true}

\begin{document}

% \conferenceinfo{HotNets 2022} {}
% \CopyrightYear{2022}
% \crdata{X}
% \date{}

%%%%%%%%%%%% THIS IS WHERE WE PUT IN THE TITLE AND AUTHORS %%%%%%%%%%%%

\title{Beyond Amdahl's Law: Achieving Superlinear Scaling with\\Distributed Self-adjusting Systems}

\author{Paper \#??} %, 6 + 1 pages}

\maketitle

\begin{abstract}
  Conventional wisdom suggests that doubling the number of workers in a distributed system can result at most 2x performance improvement, but most often less if the system does not provide perfect parallelism.  This common wisdom is codified by Amdahl's famous scaling law, asserting sublinear scaling and diminishing returns for parallelization. Several reports have indicated faster-than-linear (superlinear) scaling for various distributed applications, but most were dismissed as use-case specific artifacts, elusive interplays between memory and CPU, or mere measurement errors.

  In this paper we present the first systematic methodology to architect distributed systems to achieve superlinear scaling. Our key insight is that dispatching jobs to workers so that the locality of reference in the per-worker input streams increases, combined with self-adjusting workers that can take advantage of the higher locality to improve their own performance, yield faster-than-linear scaling. Using various off-the-shelf load balancing policies and self-adjusting algorithms from the literature, we report 100--1000x speedup when scaling certain distributed list lookup and tree search workloads to 36 CPU cores, up to 50x beyond what is predicted by Amdahl's law.  Surprisingly, we obtain nonzero scaling even when we keep the total computing power available to the system constant. By implementing an earlier self-adjusting packet classification algorithm in the Linux kernel and combining it with a simple hash-based RSS load balancer, we obtain 131x speedup on 20 cores for synthetic and 80x speedup for realistic firewall traces, 4.5x--6.3x performance improvement compared to Amdahl scaling and the default Linux packet classifier.
\end{abstract}

% \tableofcontents

% a unique combination of \emph{locality-boosting load balancing} to spread load among workers implemented using \emph{self-adjusting data structures}.
  
\input{intro.tex}

\input{background.tex}

\input{architecture.tex}

\input{case-study.tex}

\input{related.tex}

\input{conclusions.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \input{ack.tex}

\bibliographystyle{abbrv} 
\begin{small}
\bibliography{mrf}
\end{small}

% \input{appendix.tex}

\end{document}

  
