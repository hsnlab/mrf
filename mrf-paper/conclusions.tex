% !TEX ROOT = ./distributed_mrf.tex
\section{Conclusions}\label{sec:conclusions}

In this paper, we present theoretical and empirical proof that locality-boosting load balancing combined with parallel self-adjusting algorithms together yield faster-than-linear speedup in many applications on a wide range of workloads. Our main contribution is that we identify the main architectural patterns commonly appearing in the use cases where superlinear scaling emerges and synthesize these into a comprehensive and universal methodology to \emph{reproduce} it.  We then show in extensive simulations that our methodology produces orders of magnitude faster scaling than previously observed. We also show superlinear scaling on applications used widely in production. We extend the default \nftables Linux subsystem into a true self-adjusting packet classifier, which we use to identify the main workload characteristics (rule-dependency, flow diversity) that affect superlinear growth trends.  We also reproduce faster-than-linear scaling on a Memcached+PostgreSQL distributed storage system. Future research will be needed to apply our methodology in a broader range of use cases: for instance, rule-based network intrusion detection systems like Snort or Suricata \cite{10.5555/2537857.2537883} or explainable AI inferencing seem like appealing application candidates.

Finally we summarize the experience we gathered in engineering systems towards superlinear scaling in a set of generic design guidelines. (1) \emph{Optimize the load balancer for the worker implementation} (or the other way around) so that the load balancer boosts exactly the type of locality workers can exploit. A load balancer that boosts temporal locality will not improve the performance of a worker designed for spatial locality (and \emph{vice versa}). (2) \emph{Make workers' internal data structures independent} so that each can autonomously rearrange itself with respect the locality of its own input. Shared data structures will not work. For instance, \cite{ghigoff2021bmc} maintains a single cache to offload popular Memcached queries that is shared across kernel threads. This blocks parallel self-adjustment by (re)mixing the locality in the threads' input into a single unstructured workload. (3) \emph{Workers must be CPU-bounded}, otherwise the system cannot benefit from parallelization. In many cases bounded memory is also needed for self-adjustment to count (e.g., in distributed caching). (4) \emph{Avoid sequential bottlenecks} that may block speedup prematurely. For instance, we experimented with running the load-balancer for our packet classifier in the Linux kernel's RPS function, which allows better locality boosting by letting us fine-tune the partitioning function, instead of the hardware RSS that supports only hash-based partitioning. Unfortunately, the single kernel thread quickly posed a firm sequential bottleneck, well before superlinear speedup could appear.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "distributed_mrf"
%%% End:

