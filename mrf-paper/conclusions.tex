\section{Conclusions}\label{sec:conclusions}

In this paper, we present theoretical and empirical proof that locality-boosting load balancing combined with parallel self-adjusting algorithms together yield faster-than-linear speedup in many applications and a wide range of workloads. Our main contribution not necessarily stands in that we show that superlinear speedup is \emph{possible} (this has been known for quite some time), but rather that we identify the main architectural components commonly appearing in use cases where it was genuinely observed and synthesizing these into a comprehensive and universal design methodology to \emph{reproduce} it. This methodology is then used in extensive simulations, producing an order of magnitude faster scaling than previously observed. Then, we extend the default \nftables Linux subsystem into a true self-adjusting packet classifier, which we use to identify the main workload characteristics (rule-dependency, flow diversity) that affect superlinear growth trends.  Future research will be needed to apply our methodology in a broader range of use cases: for instance, rule-based network intrusion detection systems like Snort or Suricata \cite{10.5555/2537857.2537883} or explainable AI inferencing seem like appealing application candidates.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "distributed_mrf"
%%% End:

