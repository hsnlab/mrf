%\documentclass{hotnets22}
% \documentclass[sigconf,10pt]{acmart}
\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix-2020-09}
\usepackage{amsmath}
\usepackage{amsthm}

\usepackage{xfrac}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{times}  
\usepackage{hyperref}
% \usepackage{subfig}
\usepackage{tikz}
\usetikzlibrary{math}
\usepackage{pgfplots}
\usetikzlibrary{pgfplots.groupplots}
\usepackage{pgfplotstable}
\usepackage[subtle]{savetrees}
\usepackage[title]{appendix}

% axis style, ticks, etc
\pgfplotsset{every axis/.append style={
                    label style={font=\footnotesize},
                    tick label style={font=\footnotesize}  
                    }}

\usepackage{caption}
\usepackage{subcaption}
\usepackage{multirow}
\usepackage{tabularx}
\usepackage{array}
\usepackage{xspace}
\usepackage{soul}
\usepackage[normalem]{ulem}

\newcolumntype{s}{>{\hsize=.3\hsize\linewidth=\hsize}X}
\newcolumntype{D}{>{\hsize=.3\hsize\linewidth=\hsize}X}

\newcommand{\wdImg}{\dimexpr \linewidth-2\tabcolsep} %width of the image

\hypersetup{pdfstartview=FitH,pdfpagelayout=SinglePage}

\setlength\paperheight {11in}
\setlength\paperwidth {8.5in}
\setlength{\textwidth}{7in}
\setlength{\textheight}{9.25in}
\setlength{\oddsidemargin}{-.25in}
\setlength{\evensidemargin}{-.25in}

\newcommand{\rg}[1]{\textcolor{blue}{(\textbf{GR:} #1)}}
\newcommand{\vk}[1]{\textcolor{green}{(\textbf{VA:} #1)}}

\newtheorem{theorem}{Theorem}
\newtheorem{definition}{Definition}
\newtheorem{lemma}{Lemma}
\newtheorem{observation}{Observation}

% we have a big fig
\renewcommand{\floatpagefraction}{.8}%
% \renewcommand{\topfraction}{.8}
% \renewcommand{\bottomfraction}{.8}
\newcommand{\nftables}{\texttt{nftables}\xspace} 

% TODO: remove for the CR!
% \pagestyle{plain}
% \settopmatter{printfolios=true}

\begin{document}

% \conferenceinfo{HotNets 2022} {}
% \CopyrightYear{2022}
% \crdata{X}
% \date{}

%%%%%%%%%%%% THIS IS WHERE WE PUT IN THE TITLE AND AUTHORS %%%%%%%%%%%%

\title{More Bang for the Buck: 
Superlinear Scaling with Distributed Self-adjusting Systems}

\author{Paper \#619, 12 + 7 pages}
% \author{Jonas Köppeler, Maciej Pacut, Tamás Lévai, Vamsi Addanki, Stefan Schmid, Gábor Rétvári}

\maketitle

\begin{abstract}
  Conventional wisdom suggests that linear scaling of the worker pool in a distributed system can result in at most a linear performance improvement. In this paper, we present an optimization strategy for distributed systems that achieves faster-than-linear (superlinear) scaling. Our insight is that dispatching jobs to parallel workers in a way that increases the locality of reference in their inputs, and implementing the workers with a self-adjusting algorithm to exploit this higher locality, together yield superlinear scaling. We demonstrate the potential use-cases for our optimization technique in extensive simulations: scaling textbook self-adjusting algorithms we obtain 100--3,300x speedup using only 48 CPU cores, up to 70x beyond linear scaling. Then we present two operational case studies. Using our optimization strategy to scale a Memcached+PostgreSQL storage system we attain 2.3x faster than linear scaling. Then we re-engineer the Linux packet classifier to self-adjust with load, obtaining 800x speedup on synthetic traces and 220x speedup on real firewall traces with 32 CPU cores, resulting 5--25x times raw performance improvements compared to the vanilla Linux kernel.
\end{abstract}

% \tableofcontents

% a unique combination of \emph{locality-boosting load balancing} to spread load among workers implemented using \emph{self-adjusting data structures}.
  
\input{intro.tex}

\input{background.tex}

\input{architecture.tex}

\input{case-study-classifier.tex}

\input{related.tex}

\input{conclusions.tex}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \input{ack.tex}

\bibliographystyle{abbrv} 
\begin{small}
\bibliography{mrf}
\end{small}

\begin{appendices}
\input{analysis.tex}

\input{case-study-dist-caching.tex}
\end{appendices}

\end{document}
