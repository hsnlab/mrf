% !TEX ROOT = ./distributed_mrf.tex
\section{Introduction}\label{sec:introduction}

With the end of Moore's law, computing power in modern systems increasingly comes in the form of parallel processing resources.  A major obstacle faced by network engineers is how to harness this increasingly parallel computing power for scaling distributed systems \cite{265065, 10.5555/3307441.3307467, 10.1145/2815400.2815423, 10.1145/3098822.3098826, 10.5555/3154630.3154639}.

In horizontally scaled applications, a load balancer dispatches jobs across a fleet of workers that process the jobs in parallel \cite{10.5555/3235491}.  In the context of \emph{web applications}, HTTP load balancers \cite{194966, 211279, 9552525} distribute requests across a swarm of backend web servers.  % by hashing over the source IP address (``sticky sessions'').
% This way, requests from the same client will hit the same backend server, improving request locality.
% Meanwhile, resource state is maintained in a key-value store or a relational database.
Multicore \emph{OS network stacks} \cite{211263, 10.1145/3359989.3365412, 10.1145/3452296.3472914} run multiple instances of the networking logic on different CPUs and leverage the NIC to dispatch packets to CPU cores. % In order to avoid packet reordering and improve CPU cache performance, the NIC typically computes a hash over the packet header fields to select the CPU (RSS, RPS, etc.).
In \emph{sharded key-value stores} \cite{ghigoff2021bmc} different servers handle different portions of the key-space.  The system's overall goal is to achieve the greatest possible parallel speedup with a given number of workers, in order to minimize the execution time of a single task or maximize the number of completed tasks in a given time period.

Suppose a web app handles 100 requests per second using a single server. As we add another server we expect a throughput of 200 requests per second, or slightly less if the server is not perfectly parallel \cite{10.1145/1465482.1465560}. Linear scaling in this context feels almost evident: as the capacity added with horizontal scaling can be consumed at 100 percent efficiency at best, we can ``get at most equal bang for the capacity buck'' \cite{10.1145/2773212.2789974}. Seemingly defying this common wisdom, faster-than-linear (or \emph{superlinear}) scaling is commonly observed experimentally in high-performance computing applications and distributed systems \cite{scalability-analyzed, 10.5555/1012889.1012894, 271208, icsoft20, sdn-analytitcs, 556383, 6483679, 10.1007/978-3-319-77610-1, dobb-1, dobb-2, 10.1145/3627703.3629574, 7733347, 80148}).  Superlinear growth feels particularly alluring, in that it assumes a system that somehow manages to produce more work than the computer capacity available to it \cite{10.1145/2773212.2789974}.

In fact, faster-than-linear scaling is not supernatural at all. Suppose our sample web app serves a set of static assets (web pages, images, etc.) and assume each server is assigned a fixed subset of the assets, with a load-balancer carefully routing client requests to the proper server. As the number of servers increases each server perceives requests for a progressively smaller subset of the assets, which may allow it to finish servicing requests faster, say, by \emph{caching} the most popular assets in fast memory \cite{10.5555/1012889.1012894, 271208}. The combined speedup resulting from the increase of web server capacity and servers becoming faster thanks to improved cache efficiency often yields superlinear scaling \cite{556383, dobb-1, dobb-2, 7733347, 80148, wikipedia}. The trick is that the virtual job size perceived by each server gets progressively smaller as we add more servers \cite{10.1145/42411.42415, 556383, scalability-analyzed, icsoft20}. Superlinear scaling under this \emph{scaled size model} is however extremely sensitive to subtle design choices: as we show later an improper load-balancer (say, random or round-robin) or a poorly designed worker implementation (e.g., sharing a single cache across web servers) will immediately destroy the delicate superlinear scaling trend.

Despite that superlinearity is genuinely measured \cite{scalability-analyzed, sdn-analytitcs, 6483679, 10.1007/978-3-319-77610-1, 10.1145/3627703.3629574, icsoft20} and thoroughly dissected \cite{dobb-1, dobb-2, 10.1145/2773212.2789974, 556383, 7733347, 80148} in piecemeal applications, currently there is a lack of a general architectural blueprint that would help system architects to \emph{methodologically engineer distributed systems towards superlinear scaling}. In this paper we aim to fill this gap. Our motivation is that networking applications are often embarrassingly parallel, with little or no dependency between parallel workers, which may admit a massive superlinear initial growth phase before scaling eventually and unavoidably saturating on a system bottleneck.

Our main observation is that, to achieve superlinearity, one has to carefully combine an appropriate load balancing policy with a proper worker implementation. Indeed, load balancing in distributed systems is often non-arbitrary: web apps apply the ``sticky sessions'' rule to route all requests of a particular user to the same web server; %, rendering subsequent requests faster by having all per-user state available locally;
networking code commonly uses IP 5-tuple hashing on the NIC to ensure that all packets of a flow are processed on the same CPU; % that has local access to per-flow information;
and key-hashing in sharded key-value stores direct client queries for a key to the same replica. Such policies tend to make the input stream processed by the parallel workers more predictable, compared to the aggregate input processed by the system. Combining such a \emph{locality boosting load balancer} with a \emph{self-adjusting algorithm} so that workers can take advantage of the higher input predictability to adaptively improve their performance, will, as we show both theoretically and empirically, yield faster-than-linear speedup in a broad range of applications. % (see Fig.~\ref{fig:amdahl}). % One growth factor would come from the self-adjusting algorithm becoming proportionately faster as it processes a smaller and smaller subset of the inputs, and another factor would result from the fact that we throw more CPU resources to the system.

After some background on general scaling laws (\S\ref{sec:background}), we present our \emph{distributed self-adjusting system architecture}  (\S\ref{sec:architecture}). Using common list and tree search algorithms from the literature, we achieve $100$--$3300\times$ speedup in simulations, orders of magnitude surpassing plain, linear scaling. Then we extend our analysis to real systems. First we apply our methodology to achieve superlinear growth in a combined Memcached+PostgreSQL system (\S\ref{sec:dist-caching}), a result sporadically observed earlier in distributed storage systems \cite{icsoft20, wikipedia}. Then we re-engineer the default packet classifier built into the popular Linux kernel to reach superlinear scaling (\S\ref{sec:dist-classifier}). On synthetic and real-life firewall traces, our implementation shows up to $800\times$ faster than linear scaling, $5$--$25\times$ improvement beyond the default Linux firewall implementation which scales only (sub)linearly. Finally, we review related work (\S\ref{sec:related-work}) and draw the conclusions (\S\ref{sec:conclusions}). We note that all code will be available as open source after publication.

% The maximum speedup, measured as the ratio of the wall clock times of sequential and parallel execution, is formally described by Amdahl's law \cite{10.1145/1465482.1465560}. In general, the greater the sequential portion compared to the parallelizable fraction of the code, the more performance is lost compared to an ``ideal'' linear scaling, and the faster the system reaches saturation (see Fig.~\ref{fig:amdahl}). Amdahl's law has remained one of the most useful tools in the system engineering toolbox throughout the almost 60 years since its first publication \cite{10.5555/1951599, 10.1145/42411.42415, 4563876, 6280307,1580395,406581,6163449, 10.5555/775339.775386}.

% , e.g., database systems \cite{scalability-analyzed, 10.5555/1012889.1012894}, distributed caching \cite{271208, dobb-2}, SDN analytics \cite{sdn-analytitcs}, high-performance computing \cite{556383, 7733347, 6483679}, multi-robot systems \cite{10.1007/978-3-319-77610-1}, information retrieval systems \cite{dobb-1, dobb-2}, and large-scale network simulations \cite{10.1145/3627703.3629574} (see full taxonomies in \cite{7733347, 80148}).

% Many authors argue, however, that superlinear scaling is merely a~byproduct of running memory-\slash cache-bound applications on a ``bigger machine'' \cite{80148}, others are concerned that it is hard to generalize beyond a specific set use cases \cite{7733347, 80148}, and some outright dismiss faster-than-linear scaling all together \cite{gunther-hotsos, 10.1016/0167-8191(86)90024-4}, concluding that \emph{``superlinearity, although alluring, is as illusory as perpetual motion''} \cite{10.1145/2773212.2789974}.


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "distributed_mrf"
%%% End:



