\section{Case study }\label{sec:case-study}

Next, we present a case study for systematically applying the distributed self-adjusting systems architecture to a common networking problem: software packet classification \cite{gupta2001algorithms}. The goal is to demonstrate the general engineering methodology by assembling \emph{existing} techniques into a distributed self-adjusting scheme and understand when, and to what extent, superlinear scaling emerges. We consider it a success if we can robustly reproduce faster-than-linear growth on some realistic workloads. It is a stated \emph{nongoal} to conceive novel algorithms, let alone produce the fastest software packet classifier. % (that award undeniably goes to DPDK \texttt{rte\_acl} \cite{rte-acl})
Yet, our self-adjusting firewall built from existing components will prove several times faster than the default Linux kernel implementation on a wide range of workloads.

To achieve superlinear scaling we need a self-adjusting algorithm in the first place (plus a locality-boosting load balancer). From the many potential use cases % for which a self-adjusting algorithm exists
\cite{SleatorT85Splay, BentleyCL93, HesterH85, HesterH85, BentleySTW86, Avin0020, ParkM12} we eventually chose packet classification for the following reasons.  First, the default Linux firewall implementation, \nftables, uses a static doubly linked list to evaluate classifier rules, which makes it an appealing candidate for applying the move-to-front (MTF) heuristics (but see ramifications related to handling rule-dependencies below). % which will buy us the non-self-adjusting baseline for free.
Second, underlying packet classification there is an infamously difficult theoretical problem \cite{10.1145/2619239.2626294,10.1006/jagm.1996.0063, PacutVAPRS2022, 10.1145/2619239.2626294, 10.1145/1851182.1851208, 10.1145/863955.863980, gupta2001algorithms}, % , 10.1145/3359989.3365431},
and achieving superlinear speedup on such a hard problem promises massive performance gain. Third, the Linux kernel network stack offers several flexible software and hardware based load balancers for dispatching packets to parallel classifier instances running on different CPU cores \cite{rss-linux}, which we will reuse to implement the locality-boosting load balancer component. And fourth, packet classifiers are very difficult to cache \cite{1354643} (recall, caches are the ``cheap'' way to obtain superlinear scaling), which calls for a true self-adjusting packet classifier. % algorithm that goes beyond caching. % \cite{10228937}.

\subsection{The Linux packet classier}
\label{sec:sa-pack-class}

A network firewall is a means to control incoming and outgoing network traffic based on user-defined packet classifier rules. This is useful to improve security, control access, filter and protect against ongoing attacks, and log\slash monitor network activity. The main concept in a classifier is a \emph{rule}, a pair of a filter and an action (see Fig.~\ref{fig:class-sample}). A filter is essentially a user-defined regular expression defined on specific fields of the packet header or metadata, and the action decides what to do with the packets that match the filter (accept, drop, log, etc.). Rules are organized into linear rule chains. When a packet enters a chain, it is compared against the first rule of the chain. If there is a match, the corresponding action is executed and the lookup is over. Otherwise, subsequent rules are matched in the order of priority until the first match is found.

% The Linux kernel contains several built-in packet classifiers.
The \nftables kernel engine adds a simple virtual machine to the Linux kernel that uses a DSL for parsing and matching packet header fields. This makes \nftables agnostic to specific network protocols, in contrast to, e.g., \texttt{iptables}, which contains an embedded protocol parser. Currently, \nftables is the default packet classifier in most Linux distributions.

\begin{table}[t]
  \centering
  \caption{Sample firewall rule set. Source ports do not matter.}
  \label{fig:class-sample}
  \begin{small}
    \renewcommand{\tabcolsep}{2pt}
    \begin{tabular}{r|l|l|r|r|l}
      \textbf{Prio} & \textbf{Proto} & \textbf{Src IP} & \textbf{Dst IP} & \textbf{Dst Port} & \textbf{Action}\\
      \hline
      1 & UDP & 192.168.178.33   & 23.0.0.45  & 53  & ACCEPT\\
      2 & TCP & 10.10.10.0/24    & 23.0.0.45  & 443 & DROP\\
      3 & UDP & 192.168.178.0/24 & 23.0.0.45  & 53  & DROP\\
      4 & TCP & 10.10.10.10/32   & 23.0.0.45  & ANY & ACCEPT\\
      5 & IP  & 192.168.0.0/16   & 23.0.0.0/8 &     & ACCEPT\\
    \end{tabular}
  \end{small}%
\end{table}

\subsection{Self-adjusting packet classification}
\label{sec:sa-sa-pack-class}

One way to make \nftables self-adjusting would be to replace the static linked list it uses internally for rule matching with a self-adjusting list. A naive application of MTF, however, would easily break the semantics of the firewall. This is because rules in the chain may not be independent from each other, and hence may not be freely swapped \cite{10.1145/2619239.2626294}.

Consider the example in Fig.~\ref{fig:class-sample} and suppose that, initially, rules are ordered priority-wise in the list: $\langle1, 2, 3, 4, 5\rangle$. Suppose that a packet with the IP 5-tuple (192.168.0.1, 23.0.0.45, UDP, 1, 3478) enters the classifier, where the fields in the 5-tuple are IP source and destination address, protocol, and source and destination port, respectively. Rules are inspected in linear order until rule 5 is found as the first match, at which point the lookup terminates with the verdict ACCEPT. Now, a naive application of MTF would move rule 5 to the front of list, resulting in the order $\langle5, 1, 2, 3, 4\rangle$. Suppose another packet with the 5-tuple (192.168.178.1, 23.0.0.45, UDP, 1, 53) is to be processed next: this will immediately match rule 5 at the front of the list yielding the verdict ACCEPT, despite that, if matched in priority order, rule 3 would be the correct match and the verdict should be DROP. % To maintain correctness, the furthest we can move rule 5 towards the front of the list is the position immediately after its dependency, rule 3.

We say that rule $u$ is \emph{dependent} on another rule $v$ if they have overlapping match criteria in all fields, $v$ has a higher priority than $u$, and $u$ and $v$ define different actions. Such a dependency means that $u$ is not allowed to be moved before $v$ in the list, otherwise some packets may be erroneously classified. For instance, in the example of Fig.~\ref{fig:class-sample} rule 5 is dependent on rule 3, which is in turn dependent on rule 1, implying the dependency chain $5\to 3\to 1$. Similarly, rule $4$ is dependent on rule $2$. % Rule dependencies define a Directed Acyclic Graph (DAG) in the graph whose nodes are the set of rules, where there is an edge $(u, v)$ from $u$ to $v$ if $u$ is dependent on $v$ (see Fig.~\ref{fig:class-dep}).

% \begin{figure}[t]
%   \centering
%   \begin{small}
%     \begin{tikzpicture}[->,>=stealth,node distance=2.5cm, auto, every node/.style={circle,draw,minimum size=0.5cm,inner sep=2pt}]
%       % Branch 1
%       \node[circle,draw] (5) {5};
%       \node[circle,draw,right of=5] (3) {3};
%       \node[circle,draw,right of=3] (1) {1};

%       % Branch 2
%       \node[circle,draw,below of=5,yshift = 1.5cm] (4) {4};
%       \node[circle,draw,right of=4] (2) {2};

%       % Edges
%       \draw (5) -- (3);
%       \draw (3) -- (1);
%       \draw (4) -- (2);
%     \end{tikzpicture}
%   \end{small}
%   \caption{Dependency graph}%
%   \label{fig:class-dep}
% \end{figure}

A dependency-aware variant of the MTF heuristics, called the \emph{Move-recursively-Forward} (MRF) algorithm, is defined in \cite{10228937} (see Alg.~\ref{alg:mrf}). The idea is to push an accessed item forward in the list until the first dependency is reached. To prevent the item from blocking behind its direct dependency, the dependency is also moved forward until the first transitive dependency is hit. This process repeats until the head of the list is reached.  Independent rules are however free to be moved without restrictions, to the point that if there are no dependencies then MRF simplifies into a plain MTF policy.  Contrarily, if the entire rule set is a single dependency chain then no reordering is allowed and MRF degrades into a static list. In general, MRF moves frequently hit rules, with all their dependencies, to the first positions of the chain, which tends to improve lookup performance on high-locality input without jeopardizing the semantics of the classifier \cite{10228937}. In addition, MRF is ``almost''optimal in the same competitive sense as MTF, in that the best reordering one could obtain even if one knew the entire lookup sequence in advance would yield only a small constant factor improvement over MRF.

\begin{algorithm}[t]
  \caption{Move Recursively Forward (MRF)}
  \label{alg:mrf}
  \begin{small}
    \begin{algorithmic}[1]
      \Procedure{MRF}{$y$}
      \If{$y$ has no dependencies}
      \State Move $y$ to the front of the list
      \Else
      \State Let $z$ be the direct dependency of $y$
      \State Move node $y$ to position$(z) + 1$
      \State \Call{MRF}{$z$}
      \EndIf
      \EndProcedure
    \end{algorithmic}
  \end{small}
\end{algorithm}

Going back to our earlier example, after rule $5$ is hit in the list $\langle1, 2, 3, 4, 5\rangle$ MRF moves it immediately after the direct dependency $3$ along the dependency chain $5\to 3\to 1$, $3$ is moved to the position after $1$, and the recursion ends resulting the order $\langle1, 3, 2, 5, 4\rangle$. If $5$ was hit again, the lookup time would be only $4$ instead of $5$. Then, $5$ would be moved forward again, yielding the order $\langle1, 3, 5, 2, 4\rangle$ and a lookup time of $3$. Note that dependency chains can be moved by MRF independently from each other: e.g., if $4$ was hit first then we would obtain $\langle2, 1, 4, 3, 5\rangle$ in the first iteration and eventually $\langle2, 4, 1, 3, 5\rangle$, with lookup time for $4$ dropping from $4$ to $2$.

\subsection{Locality-boosting load balancing}
\label{sec:sa-rss}

An ideal locality-boosting load balancer would partition the rule set into disjoint per-worker subsets. This would minimize the size of the \emph{active rule set} at workers, which is defined as the set of rules for which a particular worker receives requests during a time window. The smaller the active rule set the fewer rules the classifier has to search through for each packet and the larger the contribution of self-adjustment to superlinear speedup. Contrarily, the larger the active rule set the more rules compete for the first positions in the self-adjusting list, which may after a certain point eliminate all self-adjustment gain, and hence superlinear scaling, all together.

In practice, there are several factors that tend to bloat workers' active rule sets. First, whenever a rule with nonzero dependencies is hit MRF adds its entire dependency chain to the active rule set. Second, packet classifiers often use wildcard rules, matching potentially a huge number of diverse traffic flows. If the load balancer dispatches two packets matching the same rule to two different workers, then both workers would have to include the same rule, with all its dependencies, in its active rule set (note that the same rule duplication problem plagues many software packet classifier algorithms \cite{10.1145/863955.863980, 820051, 10.1145/1851182.1851208, 8485947}). Designing an ideal load balancer that minimizes active rule sets, regardless of rule dependencies and flow diversity, seems difficult (but see a discussion in \S\ref{sec:related-work}).

Below, we adopt a simple hash-based load balancing scheme that implements only an ``imperfect rule set partitioning''. Our load balancer however will be fully implemented in hardware and hence run at line rate, which is crucial to minimize the overhead which in our system entirely counts towards the sequential part of the workload and limits ultimate scaling.  Later, we will show empirically that even this imperfect scheme is enough to reach superlinear speedup in many practical cases. Our load balancer reuses the Receive Side Scaling (RSS, \cite{10.1145/3359989.3365412, rss-linux}) function offered by most standard NICs. RSS evaluates a configurable hash function over a selected set of header fields per each packet. The resultant hash value is then used to index into an indirection table to select a packet queue, and the corresponding CPU core, that will process the packet. Here, the hash function may implement, e.g., the ``sticky sessions'' policy by considering only the source IP address or it may include the entire IP 5-tuple, which allows us to finetune locality-boosting in our load balancer.

\subsection{Implementation}
\label{sec:sa-nf-tables-impl}

We created a comprehensive self-adjusting packet classifier implementation on top of \nftables using the dependency-aware MRF algorithm \cite{10228937}. Each classifier instance maintains a per-CPU array of pointers that index into a shared static rule list, running the MRF algorithm on its private pointer array. This allows for running as many parallel MRF instances as there are CPUs without lock contention, with each MRF instance maintaining its own rule order. It also enables lockless rule addition\slash deletion: every time the rule list is updated we simply allocate a new pointer array at each CPU and update the list head atomically.

The original MRF algorithm uses recursion (see Alg.~\ref{alg:mrf}), which may be expensive in the Linux kernel due to the overhead of maintaining the function call stack. To avoid this overhead, we defined an iterative version of the MRF algorithm. When a rule is to be moved forward, we first check whether it can be swapped with the preceding rule. This is done by checking whether the two rules overlap using a range-based representation, which we extract from the rule's bytecode in the \nftables virtual machine. If there is an overlap then the rule cannot be moved forward so we restart the process, this time trying to move the blocking dependency forward. Otherwise, the two rules are independent so they are immediately swapped and the iteration moves to the subsequent preceding rule. Reordering terminates when we reach the first position. A more efficient implementation would be to precompute dependencies on rule insertion\slash deletion and run the MRF algorithm using the cached dependencies; implementing this optimization is for further study. %. This, however, would complicate code and make insertions more expensive. % , and may even end up being slower since recursion in the kernel can be costly due to the overhead of a potentially deep call stack.

\subsection{Evaluation}
\label{sec:sa-nf-tables-eval}

We conducted several experiments with the distributed self-adjusting packet classifier combined with a simple hash-based RSS load balancer. Our goal was to understand whether superlinear scaling can be robustly reproduced on a real network application and using real packet I/O. % Further,  we aim to determine the conditions (rule sets, flow size, etc) under which it emerges.

\begin{figure*}[t]
  \centering
  \subfloat[][acl1]{
    \input{fig/classbench-acl1.tex}
    \label{fig:classbench-acl1}
  }
  \hspace{-1em}
  \subfloat[][ipc1]{
    \input{fig/classbench-ipc1.tex}
    \label{fig:classbench-ipc1}
  }
  \hspace{-1em}
  \subfloat[][fw1]{
    \input{fig/classbench-fw1.tex}
    \label{fig:classbench-fw1}
  }
  \hspace{-1em}
  \subfloat[][Synthetic traffic]{
    \input{fig/rule-size.tex}
    \label{fig:rule-size}
  }
  \caption{Scaling on ClassBench 3 rulesets generated from different seeds, containing 5000 rules each (panel (a), (b) and (c)), and synthetic rule set with uniform traffic and different rule sizes (panel (d)). Upper row shows relative speedup and the bottom row shows absolute throughput (packet rate in million packets per sec, mpps). Note the different scales on the $y$ axes.}
  \label{fig:classbench}
\end{figure*}

\noindent
\textbf{Testbed.} %
The system-under-test (SUT) is a server equipped with a 32-core AMD EPYC 7502P@2.5 GHz CPU (64 cores with hyper-threading enabled), 128 GByte DDR4 main memory, 96 KB per-core L1 cache, 512 KB per-core L2 cache, and 128MB shared L3 cache. A server of similar configuration was used for traffic generation and for gathering the results with DPDK\slash \texttt{moongen}, connected back-to-back to the SUT over Intel XL710 for 40GbE NICs.. We used a standard Ubuntu 22.04.4 LTS OS running a patched v6.5.0 Linux kernel, replacing the default \nftables packet classifier with our own self-adjusting implementation. The benchmarks use the Tipsy network testing automation and visualization tool \cite{8468219}. Hyper-threading was disabled, unless otherwise noted.

The classifier rule sets come from two different sources. A set of \emph{realistic rule sets} were generated with \texttt{ClassBench-ng} \cite{10.1109/ANCS.2017.33, 4237157}, which accurately model the characteristics of real rule sets. ClassBench uses a seed file for stochastically tuning the statistics of the generated 5-tuple rules, including address ranges, port distribution, and rule dependencies. % , which can be further tuned using various runtime parameters.
For each rule set, a matching input packet sequence was generated using the standard Classbench tools \cite{10.1109/ANCS.2017.33,classbench-pcap}. We also used a series of \emph{synthetic rule sets} and matching packet traces for running controlled microbenchmarks, in order to observe the effect of certain classifier characteristics (e.g., active flow size or rule dependency) on scaling independently from other parameters. We generated a set of matching synthetic packet traces with uniform flow-size distribution, which, recall, represents the worst-case for self-adjustment.  In all cases the rules and packets using unroutable IP address were manually removed (otherwise, the Linux network stack would drop some packets, distorting the results). Unless otherwise noted, the benchmarks run with an RSS-based hardware load balancer using an IP 5-tuple hash.

\noindent
\textbf{Macrobenchmarks.} %
First a reality check is shown in Fig.~\ref{fig:classbench}. In particular, Fig.~\ref{fig:classbench-acl1}, Fig.~\ref{fig:classbench-ipc1} and Fig.~\ref{fig:classbench-fw1} give the speedup and the raw packet rate obtained with the default \nftables packet classifier and our self-adjusting implementation on 3 ClassBench rule sets, each containing $~5000$ rules, generated with the seeds \texttt{acl1}, \texttt{ipc1} and \texttt{fw1}, respectively. All rule and trace generation parameters were set to their default values. Recall, these rule sets and packet traces represent real-life use cases, like routers, access control lists, firewalls, etc.

Our observations are as follows. First, \emph{superlinear scaling is indeed reproducible with our distributed self-adjusting packet classifier}, with maximum speedup on 32 cores ranging from $225\times$ (about $7\times$ faster than linear) for \texttt{acl1}, to $72\times$ (about $2.2\times$ of linear) with \texttt{ipc1} and $52\times$ for \texttt{fw1} ($1.6\times$ faster than linear). In contrast, \emph{the static \nftables classifier scales almost linearly}. A closer analysis reveals a slow sublinear trend representative of an Amdahl's law profile for a very small sequential parameter ($s\sim 0.001$).

The speedup factor alone, however, does not reveal the full picture, as evidenced by Fig.~\ref{fig:classbench-fw1}. The absolute packet rate of the self-adjusting classifier on the \texttt{fw1} seed is smaller than that of the static classifier, despite the superlinear speedup. In other words, a massive spurious speedup can be obtained by improving a slow baseline.  Note, however, that this occurs only for the \texttt{fw1} seed (later we reveal, why); for the rest of the benchmarks the self-adjusting version is robustly faster even in terms of raw performance ($5.2\times$ for \texttt{acl1} and $1.4\times$ with \texttt{ipc1} on 32 cores). Nonetheless, with hyperthreading enabled we obtain $\sim\!1.5\times$ absolute packet rate improvement on 64 cores even for the \texttt{fw1} seed (not shown in the figure), indicating that, with the sufficient amount of parallel resources, distributed self-adjustment eventually surpasses static algorithms even in terms of raw performance. In other words, when scaling is superlinear even a very slow baseline becomes extremely fast ultimately.

% \noindent
% \textbf{Latency.} %
The mean per-packet latency is shown in Fig.~\ref{fig:classbench-acl1-latency}. We observe that \emph{superlinear speedup transforms into massive latency reduction}, resulting $52\times$ smaller mean packet delay on 32 cores for the \texttt{acl1} seed using the self-adjusting algorithm. In contrast, the static \nftables classifier produces a mostly flat latency profile, stabilizing at about 13ms per packet delay.

\noindent
\textbf{Rule size.} %
Fig.~\ref{fig:rule-size} shows the speedup obtained using the self-adjusting classifier on increasingly larger rule sets. The rules were generated from the following template: the source and destination IP address and source port are set to the same constant in each rule, while the UDP destination port filter of each rule $i \in [1,n]$ matches exactly one specific value, $i$. Each action was set to accept. This resulted in the below rule set structure:
\begin{small}
  \begin{tabular}{r|l|l|r|r|l}
    \textbf{Prio} & \textbf{Proto} & \textbf{Src IP} & \textbf{Dst IP} & \textbf{Dst Port} & \textbf{Action}\\
    \hline
    1 & UDP & A.B.C.D   & E.F.G.H  & 1  & ACCEPT\\
    2 & UDP & A.B.C.D   & E.F.G.H  & 2  & ACCEPT\\
    ... & ... & ...   & ...  & ...  & ...\\
  \end{tabular}
\end{small}
We obtained 3 rule sets this way, containing roughly $2$k, $5$k, and $10$k rules, respectively (the real size is a close prime to eliminate periodicity from the scaling profiles). Note that rules are independent and each rule matches exactly one flow, which represents the optimistic case for the self-adjusting classifier (see later for the pessimistic settings).  

The main takeaway is that \emph{superlinear speedup appears independently of the classifier size}, to the point that for 10k rules we see $>800\times$ speedup on 32 cores. Again, the raw performance plot casts a complete picture: the larger the rule set the greater the superlinear speedup but the smaller the absolute packet rate. Nevertheless, superlinear scaling robustly appears in terms of the raw performance as well.
% Since our goal here is to observe superlinear scaling rather than to find the fastest possible packet classifier, for the rest of the evaluations we will stick to presenting only the speedup plots.

\begin{figure*}[t]
  \centering
  \subfloat[][Latency (\texttt{acl1})]{
    \input{fig/classbench-acl1-latency.tex}
    \label{fig:classbench-acl1-latency}
  }
  \hspace{-1.4em}
  \subfloat[][Rule dependency]{
    \input{fig/rule-dependencies.tex}
    \label{fig:rule-dependencies}
  }
  \hspace{-1.4em}
  \subfloat[][Active flow size]{
    \input{fig/active-flow-size.tex}
    \label{fig:active-flow-size}
  }
  % \hspace{-1.5em}
  % \subfloat[][Zipf traffic (1997 rules)]{
  %   \input{fig/zipf.tex}
  %   \label{fig:zipf}
  % }
  \hspace{-1.4em}
  \subfloat[][Locality boosting (RSS)]{
    \input{fig/locality-boosting.tex}
    \label{fig:locality-boosting}
  }
  \caption{Microbenchmarks: (a) mean packet delay on the rule set generated from the \texttt{acl1} Classbench speed (5k rules, uniform traffic); (b) raw packet rate for 4 synthetic rule sets with increasingly long dependency chains; (c) speedup for 4 packet traces with increasingly more active flows per (independent rules); and (d) speedup with different RSS hash functions (same rules).}
  \label{fig:microbenchmark}
\end{figure*}

\noindent%
\textbf{Rule dependencies.} %
Next we turn to controlled microbenchmarks with synthetic input fine-tuned to highlight the effect of particular characteristics of the workload on scaling. The main factor affecting speedup is workers' active rule set sizes, which determines the extent to which self-adjustment can arrange recently hit rules to the front of the rule list (see \S\ref{sec:sa-sa-pack-class}), which in turn is dependent on rule-dependencies. This is because for every rule with nonzero dependencies not just the rule but all its dependencies will also become active.

To understand the effects we created 3 synthetic rule sets with increasingly long dependency chains. For every rule we add an extra $d$ overlapping rules by varying the subnet prefix length in the source IP address filter from \texttt{/32} (most specific, highest priority) to \texttt{/0} (least specific, lowest priority). This creates for every rule a chain of $d$ increasingly more specific dependencies:
\begin{small}
  \begin{tabular}{l|l|r|r|l}
    \textbf{Proto} & \textbf{Src IP} & \textbf{Dst IP} & \textbf{Dst Port} & \textbf{Action}\\
    \hline
    UDP & A.B.C.D/32   & E.F.G.H  & 1  & ACCEPT\\
    UDP & A.B.C.D/31   & E.F.G.H  & 1  & ACCEPT\\
    ... & ...   & ...  & ...  & ...\\
    UDP & A.B.C.D/0   & E.F.G.H  & 1  & ACCEPT\\
    UDP & A.B.C.D/32  & E.F.G.H  & 2  & ACCEPT\\
    ... & ...   & ...  & ...  & ...\\
  \end{tabular}
\end{small}

\noindent %
Unfortunately, this also increases the rule set size $d$ times, but this should not affect the basic superlinear speedup trends by Fig.~\ref{fig:rule-size}. We run the benchmarks with a $5$k base rule set and add $d$ dependencies per rule for $d=1$ (small-dependency), $d=2$, $d=4$ and $d=8$ (high-dep). The packet trace contains a single flow per each ``least specific'' rule at the tail of the dependency chains.

Fig.~\ref{fig:rule-dependencies} shows the absolute packet rate for the 4 synthetic rule sets. The most important observation is that, as expected, \emph{the more dependencies in the smaller the performance and the less visible the superlinear growth}, to the point that for the high-dependency rule set we see a plain linear trend (but note the simultaneous increase in the rule size). Manually checking the classifier statistics confirms that the MRF algorithm at each worker moves the active rules with all $d$ dependencies to the front of the list, removing the self-adjustment contribution for large settings of $d$ and leaving only the linear growth. In terms of speedup, however, the trend is just the opposite (not shown here): the more dependencies the greater the speedup. With 32 cores we obtain only $500\times$ speedup for $d=1$ but $1,000\times$ speedup for $d=8$, again thanks to the slow baseline.

We observed a similar slowdown when sending a huge fraction of traffic to the final ``catch-all'' rule that specifies the default action for the classifier. Since this rule depends on all other rules it cannot be moved towards the front, essentially degrading the self-adjusting classifier into a static list.

\noindent
\textbf{Flow diversity.} %
In this microbenchmark we vary the number of flows in the input packet trace per each rule of the synthetic rule set we used previously in the rule-size tests ($n=2$k). In particular, we generate 4 traces containing $0$, $5$, $50$, and $500$ uniformly distributed packets per rule, respectively. The results in Fig.~\ref{fig:active-flow-size} confirm that increasing flow diversity has negative impact on scaling: \emph{the more flows per rule the less visible the superlinear speedup}. With a modest flow diversity (1--50 per rule) we observe $400\times$--$46\times$ speedup on 32 cores. However, for $500$ flows the superlinear trend disappears and scaling degrades to linear ($32\times$ speedup on 32 cores).  We traced back the reason to the 5-tuple RSS load balancer. Recall, an optimal load balancing policy would dispatch all flows matching the same rule to the same worker, perfectly eliminating rule duplication at workers (see \S\ref{sec:sa-rss}). However, the RSS-based 5-tuple hash only ``imperfectly'' partitions the rule set: manually verifying the classifier statistics reveals that for $500$ flows per rule essentially every rule appears at every worker, completely removing the speedup contribution of self-adjustment. This leaves only the growth resulted by processing the same workload on more CPU cores, producing the linear speedup we identify in Fig.~\ref{fig:active-flow-size}.

\noindent%
\textbf{Locality boosting.} %
It seems that longer rule dependencies and growing flow diversity have negative impact on superlinear scaling. In this microbenchmark we show some clue that the negative impact can be removed using a proper locality boosting load balancer.

Fig.~\ref{fig:locality-boosting} shows the speedup for the previous high flow-diversity benchmark ($5$k independent rules, 500 uniform flows per rule) with different RSS-based hash functions. Our observations are as follows. An inadequate choice for the load balancing function removes scaling all together: e.g., the RSS hash matching on only the source IP address dispatches all input to the same worker (recall, the source IP is the same in all rules and flows), yielding no scaling at all. A better choice would be a 5-tuple hash: this at least spreads the load but, as we checked above, causes massive rule duplication across workers, constraining scaling to linear.  An optimal locality-boosting load balancer, however, would dispatch the packets matching the same rule to the same worker, removing rule duplication. For our specific rule set, such ``perfectly partitioning'' policy is a hash function that uses only the UDP destination address to generate the worker index. For this RSS hash, superlinear scaling is recovered in Fig.~\ref{fig:locality-boosting}, resulting in roughly the same speedup we observed without flow diversity (recall Fig.~\ref{fig:active-flow-size}).  This observation confirms that faster-than-linear growth appears only if the load balancer is indeed ``locality-boosting''. % (see \S\ref{sec:related-work} for a discussion on how to ensure this for an arbitrary rule set).

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "distributed_mrf"
%%% End:
