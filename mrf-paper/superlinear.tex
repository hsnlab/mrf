

\section{Superlinear Scaling of Self-adjusting\\ Distributed Systems}
\label{sec:arch-scaling}


Scaling is defined as the ratio of the completion time of the baseline system with a single machine to the completion time of the system with $k$ machines, $S(k) = T(1) / T(k)$.
Consider a single job $j$ consisting of the \emph{serial} part $s$ and the \emph{parallel} part $1-s$.
Assuming fixed problem size, task independence and divisible work, Amdahl's law states that the completion time of the system with $k$ machines cannot scale linearly
\begin{equation*}\label{eq:mtf-perf}
  \frac{T(1)}{T(k)} \le \frac1{s + \frac{1-s}{k}} \enspace .
\end{equation*}
Superlinear scaling of the parallel part of the workload would occur if $S(k) = \frac1{s + \frac{1-s}{g(k)}}$ for some $g(k) > k$. Amdahl's law rules this out.


Self-adjusting architectures seem to escape Amdahl's law, and we observe superlinear scaling in our experiments.
We observe empirical superlinear scaling for distributed caching systems~\cite{271208, 10.5555/1012889.1012894, dobb-2}. To learn more, we empirically examine an example, \emph{distributed self-adjusting list lookup}, along with a performance analysis as demonstration. Our architecture consists of a locality-boosting partitioning load-balancer (see Fig.~\ref{fig:locality-boosting-lb}) combined with a self-adjusting move-to-front list (see Fig.~\ref{fig:mtf-example}) implemented in the workers.
Similarly to distributed caching, we find that the list lookup may scale its workload superlinearly with $k$ for some inputs.

This evidence suggests to state a hypothesis that the system may achieve superlinear scaling, e.g. quadratic:
\begin{equation*}\label{eq:mtf-perf}
  \frac{T(1)}{T(k)} \overset{?}{\ge} \frac1{s + \frac{1-s}{k^2}} \enspace .
\end{equation*}
Is this possible? We investigate this question in the following sections.
We obtain a negative and a positive result:
\begin{enumerate}
\item Superlinear scaling turns out to be impossible.
Our analysis  stands that this superlinear scaling cannot continue for arbitrarily large $k$.
Rather, the superlinear scaling is just an initial phenomenon: scaling initially grows superlinearly, but eventually hits a limit for some value of $k$. See the details in Theorem~\ref{thm:superlinear}.

\item
Nonetheless, we can reap the fruits of superlinear scaling within the initial values of $k$. When load balancers boost locality of the input stream, performance of distributed self-adjusting data structures improve, and we observe superlinear scaling. For parallel self-adjusting lists, improvements can amount up to $k^2$ (see Observation~\ref{obs:list-k2}).
\end{enumerate}
To rigorously show these claims, we formulate the following mathematical model.


% The rationale for why this design achieves superlinear scaling is the following.
% Then, superlinear speedup is merely a product of two simultaneous $k\times$ speedup factors: one $k\times$ speedup comes from the self-adjusting list getting progressively faster as we add new workers (recall the ``scaled size'' model from \S\ref{sec:backgound-dist-cache}), and another $k\times$ speedup because we extend the total compute capacity available to the system $k$ times. The effective speedup is then just the multiple of the two, yielding $k^2$ times speedup in total. Plugging into Amdahl's law we get the \emph{scaling law for distributed MTF lists on uniform input} (see Fig.~\ref{fig:amdahl}):
% \begin{equation}\label{eq:mtf-perf}
  % S_l(k) = \frac{T_l(1)}{T_l(k)} = \frac1{s + \frac{1-s}{k^2}} \enspace .
% \end{equation}

% We used this scaling law as the graphical illustration for superlinear scaling in Fig.~\ref{fig:amdahl}. 
% For small values of $k$ we obtain $O(k^2)$ scaling, despite that uniform request distribution is the worst case for self-adjustments. This hints at a great future potential for networking workloads that typically exhibit highly skewed request distributions~\cite{832484}.



\subsection{The model}
\label{sec:model}

\paragraph{Architecture.}

Consider $k$ identical parallel machines $M_1, M_2, M_3, \ldots, M_k$, each having its own isolated memory and running an instance of a self-adjusting data structure $D$. A stream of requests $\sigma$ arrives to the load balancer that partitions the stream into $k$ streams $\sigma(M_1), \sigma(M_2), \ldots, \sigma(M_k)$ and dispatches them to the machines.

The load balancer is \emph{sticky}, i.e., it dispatches the requests to machines based solely on the request itself, and not on the state of the system.
Each request from $\sigma$ belongs to a universe $\mathcal{U}$. 
The load balancer is a function $f_k : \mathcal{U} \to \{1, 2, \ldots, k\}$ that partitions the universe $\mathcal{U}$ into $k$ subsets $\mathcal{U}_1, \mathcal{U}_2, \ldots, \mathcal{U}_k$ (often referred to as affinity domains).

\paragraph{Cost model.}

The time needed for the system to process a request $\sigma_t$ at time $t$ is the sum of computing the assignment of $\sigma_t$ (denoted $T(f(\sigma_t))$) and the time to schedule and process the request by $D$ at machine $M_f(\sigma_t)$ (denoted $T(D(\sigma_t)$).
The time $T(D(\sigma_t))$ depends on the internal state of the self-adjusting data structure $D$ at machine $f(\sigma_t)$.
Self-adjusting data structures change their internal state over time, hence for two identical requests coming at different times, the time to process them may differ.

The schedule finishes when all requests from $\sigma$ are processed. Some machines may be idle throughout execution, but the system is not allowed to reassign the requests to other machines.
We are interested in minimizing the completion time of the schedule.

% crucially, it's not only this:
% \[
%     \min \sum_t T(f(\sigma_t)) + T(D(\sigma_t)) \enspace .
% \]
% but more general schedule with gaps, but no reassignment


\subsection{The Scaling Law}

The definitions of $s$ and $T(1)$ are natural.
In similar fashion to Amdahl's law, we define $s$ as the serial fraction of the workload, where in our case only the load balancing is serial (total serial work is $\sum \sum_t T(f(\sigma_t))$).
Our benchmark $T(1)$ is a single self-adjusting data structure $D$ that runs on a single machine \footnote{A single self-adjusting data structure is the most natural baseline choice for the considered setting. But it differs from the baseline in Amdahl's law --- that would be a single machine simulating a non-trivial load balancer $f_k$ and $k$ independent machines to decrease the problem size. Another difference from the Amdahl's law assumptions is that the problem size is not fixed. The problem size at a machine, $T(f(\sigma_t))$, depends on the internal state of the self-adjusting data structure $D$ at time $t$ and machine $M_f(\sigma_t)$.}and processes the entire stream $\sigma$, with a trivial load balancer $f_1(\cdot) = M_1$.


Our law informally states the following: for any input $\sigma$, no self-adjusting distributed system adhering to our model can scale better than
\begin{equation*}\label{eq:mtf-perf}
  \frac{T(1)}{T(k)} \le \frac1{s + \frac{1-s}{k \cdot \ell}} \enspace ,
\end{equation*}
for some value $\ell$ that depends on how well the load balancer $f_k$ reduces the input $\sigma$.
We dedicate the Appendix~\ref{sec:apx} to the definition of $\ell$ and the proof of the theorem.
% We refer to the Appendix for formal definitions, cf. the proof of Theorem~\ref{thm:superlinear}.
The upper bound on scaling holds for all self-adjusting systems adhering to our architecture, which includes caching as a special case.




\paragraph{Consequences of the scaling law.}
Can we e.g. achieve quadratic scaling, i.e., $\ell = k$? 
Our theorem has implications that (informally) quadratic speedup is impossible to achieve for all $k$:
\begin{equation*}\label{eq:mtf-perf}
  \frac{T(1)}{T(k)} \neq \frac1{s + \frac{1-s}{k^2}} \enspace ,
\end{equation*}
The $r$ cannot grow indefinitely with $k$, and eventually the effects of load balancing ,,dry up". For each input sequence there exists a large enough value of $k$ so that adding machines no longer increases $r$ (details in Observation~\ref{obs:initial}). Hence, superlinear scaling is an initial phenomenon, and it cannot continue forever.


